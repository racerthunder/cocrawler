Crawl:
  MaxDepth: 3
  MaxTries: 4
  PageTimeout: 10
  RetryTimeout: 5
  MaxWorkers: 2
  MaxHostQPS: 10
  MaxPageSize: 1000000
  PreventCompression: False
  UpgradeInsecureRequests: 1
  ConnectTimeout: 0.  # seconds, 0.=none
#  MaxCrawledUrls: 11

Plugins:
  url_allowed: AllDomains

Fetcher:
  Nameservers:
   File:
   - dns.txt
  NameserverTries: 10
  NameserverTimeout: 3.0
  CrawlLocalhost: False  # crawl ips that resolve to localhost
  CrawlPrivate: False  # crawl ips that resolve to private networks (e.g. 10.*/8)
  DNSCacheMaxSize: 1000000

Multiprocess:
  ParseInBurnerSize: 1 # make sure the burner thread gets used 100%
  #Affinity: yes

Logging:
#  LoggingLevel: 3
  Crawllog: ../log/crawllog.jsonl
  Robotslog: ../log/robotslog.jsonl

UserAgent:
  Style: crawler
  MyPrefix: test-deep
  URL: http://example.com/cocrawler.html

